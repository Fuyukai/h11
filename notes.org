* add client_waiting_for_100_continue
* add explicit reset step before things go back to IDLE

* Closure

You or other side can close (send ConnectionClosed()) at any time.

This might be a protocol error, in which case it'll be handled like any
protocol error: it'll raise an exception and leave the Connection object in
an inconsistent state. Don't try to use it after this.

If you really just want to kill it and make it go away, go ahead and close
your socket. I can't stop you. The other side will cope.

But if you want to do an orderly shutdown, then you should do

   conn.send(ConnectionClosed())

and then wait for conn.data_to_send() to give you a None, at which point you
can close the connection (clients) or call shutdown and wait (servers).

In addition, h11 will automatically issue a close in two cases.
1) when the server reaches DONE, and the HTTP/1.1 spec says that
we need to close after this request/response. (Basically: someone has
Connection: close set, or is using HTTP/1.0.)
2) if we're in DONE or IDLE, and the other side is CLOSED.


* If we switch to our own parser:

Just always stop parsing at EndOfMessage. Either return any trailing data as part of the event, or else keep a public .unprocessed_data attribute that the user can pull out if they're throwing us away to switch to a new protocol.

and get rid of upgrade entirely, that's the user's problem


how would this look?

at each moment we have the local state +

expecting:
- Request
- InformationalResponse or Response
- Data or EndOfMessage

WAIT_FOR_100 carries the same parametrization as SENDING_BODY

maybe WAIT_FOR_100 should be a separate bit, given that it doesn't actually block client progress... or even a server state? or yeah just a flag I guess.

client state, server state, wait_for_100 flag

to read a request:
- read until crlf, then parse
to read an (Informational)Response
- read until crlf, then parse
  - then read headers
to read Data-or-EndOfMessage in HTTP10 mode:
- read any data, or EOF
to read Data-or-EndOfMessage in Content-Length mode:
- read any data

should merge states for client and server, and just have different transition tables

in general need to pass in EOF and error out if can't consume it...
there is one place where it's necessary (HTTP10 mode), some places it isn't an error (when connection is in CLOSED/IDLE/WAIT_FOR_REQUEST)


encode: depends on message, state (for DATA)


yield

* thoroughly integrating the high-level state machine

maybe it should know the framing -- SENDING_BODY should have body framing as part of it? (maybe even stash the bytes-remaining part of the content-length directly into the state, logically)
state_metadata

it should trigger socket close

maybe move each event's parse and serialization logic next to each other in the same layer?

* Error reporting

should have a single HttpError that we raise consistently from all the low-level code
and then at the top-level entry points we wrap everything in

  with errors_are_misuse:

or

  with errors_are_peer:

and that translates the HttpError into HttpUsageError versus HttpBrokenPeer

and add thorough checking (sufficient for validating untrusted peer) into the Event constructors
- e.g. require a Host header in HTTP/1.1 Request objects
- validate Content-Length is numeric and Transfer-Encoding is chunked here and both occur at most once
  (can't validate Content-Length + Transfer-Encoding override here though)
  -- this will let us drastically simplify get_framing_headers
validate that header names match the HTTP/1.1 'token' regex

I guess the one tricky point is if users create Events directly -- so maybe the lowlevel code emits the usage error, and then we switch it to brokenpeer with a context manager around receive_data?

* other notes

XX FIXME: sendfile support?
  maybe switch data_to_send to returning an iterable of stuff-to-do, which
    could be a mix of bytes-likes, sendfile objects, and CloseSocket
  and Data could accept sendfile objects as a .data field

XX FIXME: once we have the high-level state machine in place, using it to
drive our own lowlevel parser might not be that hard... it already knows
(better than libhttp_parser!) things like "next is a chunked-encoded body",
and if we are allowed to buffer and have context then HTTP tokenization is
pretty trivial I think? and everything above tokenization we are already
handling. basically the primitive we need is length-bounded regexp matching:
try to match regexp, if it fails then wait for more data to arrive in
buffer, raise HttpParseError if the buffer is already longer than the max
permitted length.

XX FIXME: replace our RuntimeError's with some more specific "you are doing
HTTP wrong" error like H2's ProtocolError. (As compared to HttpParseError,
which is "your peer is doing HTTP wrong".)

XX FIXME: might at that point make sense to split the client and server into
two separate classes?

headers to consider auto-supporting at the high-level:
- Date: https://svn.tools.ietf.org/svn/wg/httpbis/specs/rfc7231.html#header.date
    MUST be sent by origin servers who know what time it is
    (clients don't bother)
- Server
- automagic compression

should let handlers control timeouts

################################################################

Higher level stuff:
- Timeouts: waiting for 100-continue, killing idle keepalive connections,
    killing idle connections in general
    basically just need a timeout when we block on read, and if it times out
      then we close. should be settable in the APIs that block on read
      (e.g. iterating over body).
- Expect:
    https://svn.tools.ietf.org/svn/wg/httpbis/specs/rfc7231.html#rfc.section.5.1.1
  This is tightly integrated with flow control, not a lot we can do, except
  maybe provide a method to be called before blocking waiting for the
  request body?
- Sending an error when things go wrong (esp. 400 Bad Request)

- Transfer-Encoding: compress, gzip
  - but unfortunately, libhttp_parser doesn't support these at all (just
    ignores the Transfer-Encoding field and doesn't even do chunked parsing,
    so totally unfixable)
      https://stackapps.com/questions/916/why-content-encoding-gzip-rather-than-transfer-encoding-gzip
    So... this sucks, but I guess we don't support it either.

rules for upgrade are:
- when you get back an message-complete, you have to check for the upgrade
  flag
- if it's set, then there's also some trailing-data provided
- if you continue doing HTTP on the same socket, then you have to
  receive_data that trailing data again
maybe we should make this an opt-in thing in the constructor -- you have to
say whether you're prepared for upgrade handling?

also, after sending a message-complete on the server you then have to
immediately call receive_data even if there's no new bytes to pass, because
more responses might have been pipelined up.

Connection shutdown is tricky. Quoth RFC 7230:

"If a server performs an immediate close of a TCP connection, there is a
significant risk that the client will not be able to read the last HTTP
response. If the server receives additional data from the client on a fully
closed connection, such as another request that was sent by the client
before receiving the server's response, the server's TCP stack will send a
reset packet to the client; unfortunately, the reset packet might erase the
client's unacknowledged input buffers before they can be read and
interpreted by the client's HTTP parser.

"To avoid the TCP reset problem, servers typically close a connection in
stages. First, the server performs a half-close by closing only the write
side of the read/write connection. The server then continues to read from
the connection until it receives a corresponding close by the client, or
until the server is reasonably certain that its own TCP stack has received
the client's acknowledgement of the packet(s) containing the server's last
response. Finally, the server fully closes the connection."

So this needs shutdown(2). This is what data_to_send's close means -- this
complicated close dance.



EndOfMessage is tricky:
- upgrade trailing data handling
- must immediately call receive_data(b"") before blocking on socket



Implementing Expect: 100-continue on the client is also tricky: see RFC 7231
5.1.1 for details, but in particular if you get a 417 then you have to drop
the Expect: and then try again.

On the server: HTTP/1.0 + Expect: 100-continue is like the 100-continue
didn't even exist, you just ignore it.
And if you want it to go away, you should send a 4xx + Connection: close +
EOM and then we'll close it and the client won't send everything. Otherwise
you have to read it all.
#
For any Expect: value besides 100-continue, it was originally intended that
the server should blow up if it's unrecognized, but the RFC7xxx specs gave
up on this because no-one implemented it, so now servers are free to
blithely ignore unrecognized Expect: values.

Client sends (regex):
  Request Data* EndOfMessage
Server sends (regex):
  InformationalResponse* Response Data* EndOfMessage
They are linked in two places:
- client has wait-for-100-continue state (not shown) where the transition
  out is receiving a InformationalResponse or Response (or timeout)
- *both* EndOfMessage's have to arrive before *either* machine returns to
  the start state.
