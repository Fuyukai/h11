protocol switch:
really 1 event is client requests connect/upgrade
and 1 event is server accepting or rejecting it

Request sends server into
  MIGHT_SWITCH_PROTOCOL
with has transitions:
- actual switch: -> SWITCHED_PROTOCOL
- denied (always a Response): -> SEND_BODY
- InformationalResponse: loop

client_potential_protocol_switch_pending = "upgrade" | "CONNECT" | False
server Response with protocol_switch=False
  sets client_potential_protocol_switch_pending = False
    pushes client out of special state (if this is different?)
server Response with protocol_switch=("upgrade" | "CONNECT")
  checks that this matches the client's


client_might_switch_protocol = False | "upgrade" | "CONNECT"
can't be in DONE/DONE with client_might_switch_protocol truthy, so prepare_to_reuse is unaffected...



can_reuse sounds like it should be boolean :-( :-(
  reuseable? also bool
  reuse_schedule
  reuse_when
and maybe it should tell you what needs to happen -- I guess server is mostly interested in "is this reusable now", "could it be made reusable just by reading from the socket" (or maybe even just "is this reusable now")
client ditto?
  which is: I'm in DONE (this automatically handles keep-alive issue)
our problem is we have two false answers and one true answer
maybe we should invert it so we have two true answers and one false answer:
  in_use = {False, "drain", "something something closed? meh"}

for non-reuse-related reasons, server also is interested in knowing whether the handler actually completed a response, because if not then it should log an error
server also needs to check for MUST_CLOSE and actually close when it sees it (or I guess maybe this is the same response as any other non-DONE state when the handler returns?)

still not 100% happy with prepare_to_reuse

should move the dot drawing code into docs/

pondering moving headers to be (default)dict of lowercase bytestrings -> ordered lists of bytestrings
I guess we should get some benchmarks/profiles first, since one of the motivations would be to eliminate all these linear scans and reallocations we use when dealing with headers

XX TODO:
   A server MUST NOT send a Transfer-Encoding header field in any
   response with a status code of 1xx (Informational) or 204 (No
   Content).  A server MUST NOT send a Transfer-Encoding header field in
   any 2xx (Successful) response to a CONNECT request (Section 4.3.6 of
   [RFC7231]).

   A server MUST NOT send a Content-Length header field in any response
   with a status code of 1xx (Informational) or 204 (No Content).  A
   server MUST NOT send a Content-Length header field in any 2xx
   (Successful) response to a CONNECT request (Section 4.3.6 of
   [RFC7231]).

http://coad.measurement-factory.com/details.html

* Closure

You or other side can close (send ConnectionClosed()) at any time.

This might be a protocol error, in which case it'll be handled like any
protocol error: it'll raise an exception and leave the Connection object in
an inconsistent state. Don't try to use it after this.

If you really just want to kill it and make it go away, go ahead and close
your socket. I can't stop you. The other side will cope.

But if you want to do an orderly shutdown, then you should do

   conn.send(ConnectionClosed())

and then wait for conn.data_to_send() to give you a None, at which point you
can close the connection (clients) or call shutdown and wait (servers).

^^ actually this makes no sense -- it's not necessary to ever send ConnectionClosed(), because conn.data_to_send() is always fully up-to-date with no internal buffering. If there were internal buffering then nothing would work, because we have no way to signal that more data is available. So the lack of buffering is a fundamental guarantee of the API, which means that any time you could do send(ConnectionClosed()), you could also just close the connection. I guess the one exception would be if send() and data_to_send() were like, in different threads, so this was a communication channel between them... but Connection objects aren't even thread-safe.
Oh, but you definitely should send ConnectionClosed() if you're doing a half-shutdown and continuing to read.

In addition, h11 will automatically issue a close in two cases.
1) when the server reaches DONE, and the HTTP/1.1 spec says that
we need to close after this request/response. (Basically: someone has
Connection: close set, or is using HTTP/1.0.)
2) if we're in DONE or IDLE, and the other side is CLOSED.
^^ this also makes no sense -- if we spontaneously emit some data_to_send, then there's no way for the user to know this. So we can't do that.

Instead, we should add a new state MUST_CLOSE, and the rules:

1) when a party reaches DONE, and the HTTP/1.1 spec says that they must close, then they automagically go to the MUST_CLOSE state
2) if either party is in DONE or IDLE and the other is in CLOSED, then the party that is not CLOSED automatically goes to the MUST_CLOSE state

* notes for building something on top of this

headers to consider auto-supporting at the high-level:
- Date: https://svn.tools.ietf.org/svn/wg/httpbis/specs/rfc7231.html#header.date
    MUST be sent by origin servers who know what time it is
    (clients don't bother)
- Server
- automagic compression

should let handlers control timeouts

################################################################

Higher level stuff:
- Timeouts: waiting for 100-continue, killing idle keepalive connections,
    killing idle connections in general
    basically just need a timeout when we block on read, and if it times out
      then we close. should be settable in the APIs that block on read
      (e.g. iterating over body).
- Expect:
    https://svn.tools.ietf.org/svn/wg/httpbis/specs/rfc7231.html#rfc.section.5.1.1
  This is tightly integrated with flow control, not a lot we can do, except
  maybe provide a method to be called before blocking waiting for the
  request body?
- Sending an error when things go wrong (esp. 400 Bad Request)

Connection shutdown is tricky. Quoth RFC 7230:

"If a server performs an immediate close of a TCP connection, there is a
significant risk that the client will not be able to read the last HTTP
response. If the server receives additional data from the client on a fully
closed connection, such as another request that was sent by the client
before receiving the server's response, the server's TCP stack will send a
reset packet to the client; unfortunately, the reset packet might erase the
client's unacknowledged input buffers before they can be read and
interpreted by the client's HTTP parser.

"To avoid the TCP reset problem, servers typically close a connection in
stages. First, the server performs a half-close by closing only the write
side of the read/write connection. The server then continues to read from
the connection until it receives a corresponding close by the client, or
until the server is reasonably certain that its own TCP stack has received
the client's acknowledgement of the packet(s) containing the server's last
response. Finally, the server fully closes the connection."

So this needs shutdown(2). This is what data_to_send's close means -- this
complicated close dance.


Implementing Expect: 100-continue on the client is also tricky: see RFC 7231
5.1.1 for details, but in particular if you get a 417 then you have to drop
the Expect: and then try again.

On the server: HTTP/1.0 + Expect: 100-continue is like the 100-continue
didn't even exist, you just ignore it.
And if you want it to go away, you should send a 4xx + Connection: close +
EOM and then we'll close it and the client won't send everything. Otherwise
you have to read it all.
#
For any Expect: value besides 100-continue, it was originally intended that
the server should blow up if it's unrecognized, but the RFC7xxx specs gave
up on this because no-one implemented it, so now servers are free to
blithely ignore unrecognized Expect: values.

Client sends (regex):
  Request Data* EndOfMessage
Server sends (regex):
  InformationalResponse* Response Data* EndOfMessage
They are linked in two places:
- client has wait-for-100-continue state (not shown) where the transition
  out is receiving a InformationalResponse or Response (or timeout)
- *both* EndOfMessage's have to arrive before *either* machine returns to
  the start state.
